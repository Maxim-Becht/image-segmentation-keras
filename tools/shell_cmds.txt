// Windows shell command for removing last 2 characters of ervery .png file in folder ("_L" in CamVid labeld images, prepared for image-segmentation-keras project training validating and testing dataloader (dataset) setup)
get-childitem *.png | rename-item -newname { $_.basename.substring(0,$_.basename.length-2) + $_.extension }


// For SegNet_CamVid model:
// datasets:
python -m keras_segmentation verify_dataset --images_path="data/datasets/CamVid/train/raw/" --segs_path="data/datasets/CamVid/train/labeled/" --n_classes=32
python -m keras_segmentation visualize_dataset --images_path="data/datasets/CamVid/train/raw/" --segs_path="data/datasets/CamVid/train/labeled/" --n_classes=32

// training:
python -m keras_segmentation train --checkpoints_path="data\trained\SegNet_CamVid\v_1\" --auto_resume_checkpoint --train_images="data/datasets/CamVid/train/raw/" --train_annotations="data/datasets/CamVid/train/labeled/" --val_images="data/datasets/CamVid/val/raw/" --val_annotations="data/datasets/CamVid/val/labeled/" --n_classes=32 --input_height=720 --input_width=960 --model_name="segnet" --epochs=10

python -m keras_segmentation train --checkpoints_path="data\trained\SegNet_VGG16_CamVid\v_1\" --auto_resume_checkpoint --train_images="data/datasets/CamVid/train/raw/" --train_annotations="data/datasets/CamVid/train/labeled/" --val_images="data/datasets/CamVid/val/raw/" --val_annotations="data/datasets/CamVid/val/labeled/" --n_classes=32 --input_height=704 --input_width=960 --model_name="vgg_segnet" --epochs=10

// evaluation (IoU):
python -m keras_segmentation evaluate_model --checkpoints_path="data\trained\SegNet_VGG16_CamVid\v_1\" --images_path="data/datasets/CamVid/test/raw/" --segs_path="data/datasets/CamVid/test/labeled/"

// predictions:
python -m keras_segmentation predict --checkpoints_path="data\trained\SegNet_CamVid\v_1\best\" --input_path="data/datasets/CamVid/test/raw/" --output_path="data/datasets/CamVid/predict/SegNet/"
python -m keras_segmentation predict --checkpoints_path="data\trained\SegNet_VGG16_CamVid\v_1\" --input_path="data/datasets/CamVid/test/raw/" --output_path="data/datasets/CamVid/predict/SegNet_VGG16/"


// For SegNet_TrimBot model:
// datasets:
python -m keras_segmentation verify_dataset --images_path="data/datasets/TrimBot/train/raw/" --segs_path="data/datasets/TrimBot/train/labeled/" --n_classes=10
python -m keras_segmentation visualize_dataset --images_path="data/datasets/TrimBot/train/raw/" --segs_path="data/datasets/TrimBot/train/labeled/" --n_classes=10

// training:
python -m keras_segmentation train --checkpoints_path="data\trained\SegNet_TrimBot\v_1\" --auto_resume_checkpoint --train_images="data/datasets/TrimBot/train/raw/" --train_annotations="data/datasets/TrimBot/train/labeled/" --val_images="data/datasets/TrimBot/val/raw/" --val_annotations="data/datasets/TrimBot/val/labeled/" --n_classes=10 --input_height=480 --input_width=640 --model_name="segnet" --epochs=10

python -m keras_segmentation train --checkpoints_path="data\trained\SegNet_VGG16_TrimBot\v_1\" --auto_resume_checkpoint --train_images="data/datasets/TrimBot/train/raw/" --train_annotations="data/datasets/TrimBot/train/labeled/" --val_images="data/datasets/TrimBot/val/raw/" --val_annotations="data/datasets/TrimBot/val/labeled/" --n_classes=10 --input_height=480 --input_width=640 --model_name="vgg_segnet" --epochs=10

// evaluation (IoU):
python -m keras_segmentation evaluate_model --checkpoints_path="data\trained\SegNet_VGG16_TrimBot\v_1\" --images_path="data/datasets/TrimBot/test/raw/" --segs_path="data/datasets/TrimBot/test/labeled/"

// predictions:
python -m keras_segmentation predict --checkpoints_path="data\trained\SegNet_TrimBot\v_1\" --input_path="data/datasets/TrimBot/test/raw/" --output_path="data/datasets/TrimBot/predict/"



// For SegNet_STIHL model:
// datasets:
color_masks_full:
python -m keras_segmentation verify_dataset --images_path="data/datasets/STIHL_SemSeg_Data/color_masks/train/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/color_masks/train/labeled/" --n_classes=23
python -m keras_segmentation verify_dataset --images_path="data/datasets/STIHL_SemSeg_Data/color_masks/val/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/color_masks/val/labeled/" --n_classes=23
python -m keras_segmentation verify_dataset --images_path="data/datasets/STIHL_SemSeg_Data/color_masks/test/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/color_masks/test/labeled/" --n_classes=23

python -m keras_segmentation visualize_dataset --images_path="data/datasets/STIHL_SemSeg_Data/color_masks/train/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/color_masks/train/labeled/" --n_classes=23
python -m keras_segmentation visualize_dataset --images_path="data/datasets/STIHL_SemSeg_Data/color_masks/val/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/color_masks/val/labeled/" --n_classes=23
python -m keras_segmentation visualize_dataset --images_path="data/datasets/STIHL_SemSeg_Data/color_masks/test/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/color_masks/test/labeled/" --n_classes=23

python -m keras_segmentation train --checkpoints_path="data\trained\SegNet_STIHL\v_1\" --auto_resume_checkpoint --train_images="data/datasets/STIHL_SemSeg_Data/color_masks/train/raw/" --train_annotations="data/datasets/STIHL_SemSeg_Data/color_masks/train/labeled/" --val_images="data/datasets/STIHL_SemSeg_Data/color_masks/val/raw/" --val_annotations="data/datasets/STIHL_SemSeg_Data/color_masks/val/labeled/" --n_classes=23 --input_height=648 --input_width=486 --model_name="segnet" --ignore_zero_class --epochs=5

python -m keras_segmentation evaluate_model --checkpoints_path="data\trained\SegNet_STIHL\v_1\" --images_path="data/datasets/STIHL_SemSeg_Data/color_masks/test/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/color_masks/test/labeled/"

python -m keras_segmentation predict --checkpoints_path="data\trained\SegNet_STIHL\v_1\" --input_path="data/datasets/STIHL_SemSeg_Data/color_masks/test/raw/" --output_path="data/datasets/STIHL_SemSeg_Data/color_masks/predict/"
python -m keras_segmentation visualize_dataset --images_path="data/datasets/STIHL_SemSeg_Data/color_masks/test/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/color_masks/predict/" --n_classes=23

color_masks_simplyfied:
python -m keras_segmentation verify_dataset --images_path="data/datasets/STIHL_SemSeg_Data/train/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/train/color_masks_simplyfied/" --n_classes=3
python -m keras_segmentation visualize_dataset --images_path="data/datasets/STIHL_SemSeg_Data/train/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/train/color_masks_simplyfied/" --n_classes=3
color_masks_simplyfied_3:
python -m keras_segmentation verify_dataset --images_path="data/datasets/STIHL_SemSeg_Data/train/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/train/color_masks_simplyfied_3/" --n_classes=4
python -m keras_segmentation visualize_dataset --images_path="data/datasets/STIHL_SemSeg_Data/train/raw/" --segs_path="data/datasets/STIHL_SemSeg_Data/train/color_masks_simplyfied_3/" --n_classes=4

// training:
python -m keras_segmentation train --checkpoints_path="data\trained\SegNet_VGG16_STIHL\v_1\" --auto_resume_checkpoint --train_images="data/datasets/STIHL_SemSeg_Data/train/raw/" --train_annotations="data/datasets/STIHL_SemSeg_Data/train/color_mask/" --val_images="data/datasets/STIHL_SemSeg_Data/val/raw/" --val_annotations="data/datasets/STIHL_SemSeg_Data/val/labeled/" --n_classes=3 --input_height=648 --input_width=486 --model_name="vgg_segnet" --epochs=5

// evaluation (IoU):
python -m keras_segmentation evaluate_model --checkpoints_path="data\trained\SegNet_VGG16_STIHL\v_1\" --images_path="data/datasets/TrimBot/test/raw/" --segs_path="data/datasets/TrimBot/test/labeled/"

// predictions:
python -m keras_segmentation predict --checkpoints_path="data\trained\SegNet_VGG16_STIHL\v_1\" --input_path="data/datasets/TrimBot/test/raw/" --output_path="data/datasets/TrimBot/predict/"
